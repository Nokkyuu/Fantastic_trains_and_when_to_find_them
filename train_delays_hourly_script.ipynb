{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import schedule\n",
    "import datetime\n",
    "import threading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time in Berlin: 2024-07-03 11:07:47.082382+02:00\n"
     ]
    }
   ],
   "source": [
    "import pytz\n",
    "berlin_tz = pytz.timezone('Europe/Berlin')\n",
    "berlin_time = datetime.datetime.now(berlin_tz)\n",
    "print(\"Current time in Berlin:\", berlin_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = pd.read_csv(\"data/fromAPI/StaDa.csv\")\n",
    "stations_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping lower categories - comment out if you want all\n",
    "stations_df.drop(labels=stations_df.query(\"category == 6\").index, axis=0,inplace=True)\n",
    "stations_df.drop(labels=stations_df.query(\"category == 7\").index, axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get relevant lists from df\n",
    "eva_nrs = stations_df[\"eva_nr\"].values\n",
    "names = stations_df[\"name\"].values\n",
    "states = stations_df[\"state\"].values\n",
    "cities = stations_df[\"city\"].values\n",
    "zipcodes = stations_df[\"zipcode\"].values\n",
    "longs = stations_df[\"long\"].values\n",
    "lats = stations_df[\"lat\"].values\n",
    "cats = stations_df[\"category\"].values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API client ID and Secret\n",
    "client_id = '5cf21bb577a46a3f0263677e5bee0969'\n",
    "client_secret = '0229d92a983df1a6681e56ba6a390135'\n",
    "#Header for request\n",
    "headers={\n",
    "        \"DB-Api-Key\": client_secret,\n",
    "        \"DB-Client-Id\": client_id,\n",
    "        \"accept\": \"application/xml\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start data collection at240703 10\n"
     ]
    }
   ],
   "source": [
    "def job():\n",
    "    \n",
    "    grabtime = f\"{datetime.datetime.now(berlin_tz).hour}\"\n",
    "    if len(grabtime) < 2 : grabtime = f\"0{grabtime}\"\n",
    "    plan_data = [] #list initializing\n",
    "    change_data = []\n",
    "    buglog = []\n",
    "    date = datetime.datetime.now(berlin_tz).strftime(\"%y%m%d\")\n",
    "    print(f\"start data collection at{date} {grabtime}\")\n",
    "    for i in range(len(eva_nrs)):\n",
    "        url_change = f\"https://apis.deutschebahn.com/db-api-marketplace/apis/timetables/v1/fchg/{eva_nrs[i]}\"\n",
    "        url_plan = f\"https://apis.deutschebahn.com/db-api-marketplace/apis/timetables/v1/plan/{eva_nrs[i]}/{date}/{grabtime}\"\n",
    "\n",
    "        try:\n",
    "            response_plan = requests.get(url_plan, headers=headers)\n",
    "            response_change = requests.get(url_change, headers=headers)\n",
    "        except:\n",
    "            bug = f\"{names[i]} connection skipped\"\n",
    "            buglog.append(bug)\n",
    "            print(bug)\n",
    "            time.sleep(0.2)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            plan_root = ET.fromstring(response_plan.content)\n",
    "        except:\n",
    "            bug = f\"{names[i]} plan skipped\"\n",
    "            print(bug)\n",
    "            buglog.append(bug)\n",
    "            time.sleep(0.2)\n",
    "            continue\n",
    "\n",
    "        for s in plan_root.findall('.//s'):\n",
    "            s_id = s.get('id')\n",
    "            s_eva = s.get('eva')\n",
    "            ar = s.find('ar')\n",
    "            if ar is not None:\n",
    "                ar_pt = ar.get('pt')\n",
    "                ar_ppth = ar.get('ppth')\n",
    "            else:\n",
    "                ar_pt = ar_ppth = None\n",
    "            dp = s.find('dp')\n",
    "            if dp is not None:\n",
    "                dp_pt = dp.get('pt')\n",
    "                dp_l = dp.get('l')\n",
    "            else:\n",
    "                dp_pt = dp_l = None  \n",
    "            # Append the extracted data to the list\n",
    "            plan_data.append([s_id, ar_pt, dp_pt, dp_l, ar_ppth, eva_nrs[i], cats[i], names[i], states[i], cities[i], zipcodes[i], longs[i], lats[i]])\n",
    "\n",
    "        try:\n",
    "            change_root = ET.fromstring(response_change.content)\n",
    "        #change_root = change_tree.getroot()\n",
    "        except:\n",
    "            bug = f\"{names[i]} change skipped\"\n",
    "            buglog.append(bug)\n",
    "            print(bug)\n",
    "            time.sleep(0.2)\n",
    "            continue\n",
    "        # Iterate over each 's' element in the XML\n",
    "        for s in change_root.findall('.//s'):\n",
    "            s_id = s.get('id')\n",
    "            s_eva = s.get('eva')\n",
    "\n",
    "            m = s.find('m')\n",
    "            if m is not None:\n",
    "                cat = m.get('cat')\n",
    "            else:\n",
    "                cat = None\n",
    "\n",
    "            ar = s.find('ar')\n",
    "            if ar is not None:\n",
    "                ar_ct = ar.get('ct')#planned arrival\n",
    "            else:\n",
    "                ar_ct = None\n",
    "            \n",
    "            dp = s.find('dp')\n",
    "            if dp is not None:\n",
    "                dp_ct = dp.get('ct')\n",
    "            else:\n",
    "                dp_ct = None\n",
    "            \n",
    "            change_data.append([s_id, ar_ct, dp_ct, cat])\n",
    "        \n",
    "        time.sleep(0.1)\n",
    "\n",
    "\n",
    "\n",
    "    columns = ['ID', 'arrival', \"departure\", \"train\", \"path\",'eva_nr', \"category\", \"name\", \"state\", \"city\", \"zip\", \"long\", \"lat\"]\n",
    "    plan_df = pd.DataFrame(plan_data, columns=columns)\n",
    "    plan_df['arrival'] = pd.to_datetime(plan_df['arrival'], format='%y%m%d%H%M')\n",
    "    plan_df['departure'] = pd.to_datetime(plan_df['departure'], format='%y%m%d%H%M')\n",
    "\n",
    "    columns = ['ID', 'arrival', \"departure\", \"info\"]\n",
    "    change_df = pd.DataFrame(change_data, columns=columns)\n",
    "    change_df['arrival'] = pd.to_datetime(change_df['arrival'], format='%y%m%d%H%M')\n",
    "    change_df['departure'] = pd.to_datetime(change_df['departure'], format='%y%m%d%H%M')\n",
    "\n",
    "    delay_df = pd.merge(plan_df, change_df, how='left', on=\"ID\", suffixes=('_plan', '_change'))\n",
    "    delay_df['depature_delay_m'] = delay_df['departure_change'] - delay_df['departure_plan']\n",
    "    delay_df['arrival_delay_m'] = delay_df['arrival_change'] - delay_df['arrival_plan']\n",
    "\n",
    "    #sorting columns\n",
    "    delay_df = delay_df[['ID', 'train', 'path', 'eva_nr', \"category\", 'name', 'state', 'city', 'zip', 'long', 'lat', 'arrival_plan', 'departure_plan', 'arrival_change','departure_change',  'arrival_delay_m', 'depature_delay_m', \"info\"]]\n",
    "\n",
    "    delay_df[\"depature_delay_m\"] = delay_df[\"depature_delay_m\"].dt.total_seconds()/60\n",
    "    delay_df[\"depature_delay_m\"] = delay_df[\"depature_delay_m\"].fillna(value=0)\n",
    "    delay_df[\"depature_delay_m\"] = delay_df[\"depature_delay_m\"].astype(int)\n",
    "    delay_df[\"arrival_delay_m\"] = delay_df[\"arrival_delay_m\"].dt.total_seconds()/60\n",
    "    delay_df[\"arrival_delay_m\"] = delay_df[\"arrival_delay_m\"].fillna(value=0)\n",
    "    delay_df[\"arrival_delay_m\"] = delay_df[\"arrival_delay_m\"].astype(int)\n",
    "    delay_df[\"eva_nr\"] = delay_df[\"eva_nr\"].astype(int)\n",
    "\n",
    "    delay_df.to_csv(f\"data/fromAPI/hourly2/{date}_{grabtime}.csv\")\n",
    "\n",
    "    file_name = f\"data/fromAPI/hourly2/{date}_{grabtime}_log.txt\"\n",
    "\n",
    "    with open(file_name, \"w\") as file:\n",
    "        for item in buglog:\n",
    "            file.write(f\"{item}\\n\")\n",
    "\n",
    "schedule.every().hour.at(\":10\").do(job)\n",
    "stop_run = False\n",
    "# Function to keep the script running\n",
    "\n",
    "def run_scheduler():\n",
    "    global stop_run\n",
    "    while not stop_run:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(10)  # Sleep for 1 second to prevent high CPU usage\n",
    "\n",
    "# Run the scheduler in a non-blocking way\n",
    "scheduler_thread = threading.Thread(target=run_scheduler)\n",
    "scheduler_thread.start()\n",
    "\n",
    "def stop_scheduler():\n",
    "    global stop_run\n",
    "    stop_run = True\n",
    "    scheduler_thread.join()\n",
    "\n",
    "# Example of stopping the scheduler after some time (e.g., 1 hour)\n",
    "time.sleep(3600*72)  # Let it run for 1 hour\n",
    "stop_scheduler()\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
